{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python (env japan-nlp)",
      "language": "python",
      "name": "py-dku-venv-japan-nlp"
    },
    "associatedRecipe": "compute_TF_IDF_scores",
    "creator": "admin",
    "createdOn": 1622813273863,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {}
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import dataiku\n",
        "import pandas as pd, numpy as np\n",
        "from dataiku import pandasutils as pdu\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim import corpora\n",
        "from gensim import models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Read recipe inputs\n",
        "df \u003d dataiku.Dataset(\"ramen_clusters_named\").get_dataframe()\n",
        "raw_ramen_df \u003d dataiku.Dataset(\"raw_ramen\").get_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "client \u003d dataiku.api_client()\n",
        "project \u003d client.get_project(dataiku.get_custom_variables()[\u0027projectKey\u0027])\n",
        "project_variables \u003d project.get_variables()\n",
        "clusters_to_select \u003d project_variables[\u0027standard\u0027][\u0027clusters_to_select\u0027]\n",
        "list_vocabs \u003d df[df[\u0027cluster_labels\u0027].isin([\u0027営業形態\u0027, \u0027味・具材\u0027])][\u0027words_concat\u0027].values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "ramen_word \u003d list_vocabs[0].split(\",\") + list_vocabs[1].split(\",\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "folder_path \u003d dataiku.Folder(\"aLTWBozg\").get_path()\n",
        "text_path \u003d folder_path + \"/ramen_corpus.txt\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "f \u003d open(text_path,\u0027r\u0027,encoding\u003d\"utf-8\")\n",
        "trainings \u003d []"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "for i,data in enumerate(f):\n",
        "    word \u003d data.replace(\"\u0027\",\u0027\u0027).replace(\u0027[\u0027,\u0027\u0027).replace(\u0027]\u0027,\u0027\u0027).replace(\u0027 \u0027,\u0027\u0027).replace(\u0027\\n\u0027,\u0027\u0027).split(\",\")\n",
        "    trainings.append([i for i in word if i in ramen_word])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "len(trainings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "dictionary \u003d corpora.Dictionary(trainings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "dictionary.num_docs, dictionary.num_pos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# saving the dictionary in a folder\n",
        "# for later use\n",
        "folder_path \u003d dataiku.Folder(\"POe5uF4H\").get_path()\n",
        "filename \u003d folder_path + \"/ramen_dictionary\"\n",
        "dictionary.save(filename)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "corpus \u003d list(map(dictionary.doc2bow, trainings))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "test_model \u003d models.TfidfModel(corpus) # fit tfidf model\n",
        "\n",
        "# saving tf-idf model\n",
        "tf_idf_folder_path \u003d dataiku.Folder(\"tMMk2S0T\").get_path()\n",
        "path_tf_idf \u003d tf_idf_folder_path + \"/tf_idf\"\n",
        "test_model.save(path_tf_idf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "corpus_tfidf \u003d test_model[corpus] # apply model to the corpus (just like \u0027transform\u0027 in scikit-learn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# id-\u003e単語へ変換\n",
        "texts_tfidf \u003d [] # id -\u003e 単語表示に変えた文書ごとのTF-IDF\n",
        "for doc in corpus_tfidf:\n",
        "    text_tfidf \u003d []\n",
        "    for word in doc:\n",
        "        text_tfidf.append([dictionary[word[0]],word[1]])\n",
        "    texts_tfidf.append(text_tfidf)\n",
        "\n",
        "from operator import itemgetter\n",
        "\n",
        "texts_tfidf_sorted_top20 \u003d []\n",
        "\n",
        "# TF-IDF値を高い順に並び替え上位単語20個に絞る。\n",
        "# 各ラーメン店のレビューにおいて、TF-IDF値の高い20単語だけが残る。\n",
        "for i in range(len(texts_tfidf)):\n",
        "    soted \u003d sorted(texts_tfidf[i], key\u003ditemgetter(1), reverse\u003dTrue)\n",
        "    soted_top20 \u003d soted[:20]\n",
        "    word_list \u003d []\n",
        "    for k in range(len(soted_top20)):\n",
        "        word \u003d soted_top20[k][0]\n",
        "        word_list.append(word)\n",
        "    texts_tfidf_sorted_top20.append(word_list)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "ramen_by_restaurant \u003d raw_ramen_df.groupby([\u0027store_name\u0027, \u0027address\u0027, \u0027ward\u0027, \u0027score\u0027, \u0027review_cnt\u0027])[\u0027review\u0027].apply(list).apply(\u0027 \u0027.join).reset_index().sort_values(\u0027score\u0027, ascending\u003dFalse)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "ramen_by_restaurant.shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "ramen_by_restaurant.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "ramen_by_restaurant[\u0027texts_tfidf_sorted_top20\u0027] \u003d texts_tfidf_sorted_top20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "ramen_by_restaurant[\u0027id\u0027] \u003d [\u0027ID-\u0027 + str(i + 1).zfill(6) for i in range(len(ramen_by_restaurant.index))]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "ramen_by_restaurant \u003d ramen_by_restaurant.reset_index(drop\u003dTrue)\n",
        "\n",
        "\n",
        "py_recipe_output \u003d dataiku.Dataset(\"reviews_TF_IDF\")\n",
        "py_recipe_output.write_with_schema(ramen_by_restaurant)"
      ]
    }
  ]
}