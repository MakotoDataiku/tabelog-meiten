{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (env japan-nlp)",
      "name": "py-dku-venv-japan-nlp",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.6.8",
      "name": "python",
      "pygments_lexer": "ipython3",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "tags": [
      "recipe-editor"
    ],
    "associatedRecipe": "compute_TF_IDF_scores",
    "createdOn": 1622813273863,
    "hide_input": false,
    "customFields": {},
    "creator": "admin",
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom gensim import corpora\nfrom gensim import models"
      ],
      "outputs": []
    },
    {
      "execution_count": 7,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs\nramen_clusters_named \u003d dataiku.Dataset(\"ramen_clusters_named\")\ndf \u003d ramen_clusters_named.get_dataframe()\n# raw_ramen_df \u003d dataiku.Dataset(\"raw_ramen\").get_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "evalue": "Unable to fetch schema for RAMENMEITEN.ramen_clusters_named: b\u0027Ticket not given or unrecognized. Force reload the notebook.\u0027",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-7-3537895c6689\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read recipe inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mramen_clusters_named\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mdataiku\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ramen_clusters_named\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mramen_clusters_named\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# raw_ramen_df \u003d dataiku.Dataset(\"raw_ramen\").get_dataframe()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/dataiku/Design/dataiku-dss-9.0.3-osx/python/dataiku/core/dataset.py\u001b[0m in \u001b[0;36mget_dataframe\u001b[0;34m(self, columns, sampling, sampling_column, limit, ratio, infer_with_pandas, parse_dates, bool_as_str, float_precision)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mparse_dates\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0minfer_with_pandas\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0minfer_with_pandas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 405\u001b[0;31m             bool_as_str\u003dbool_as_str) # see df_from_split_desc\n\u001b[0m\u001b[1;32m    406\u001b[0m         with self._stream(infer_with_pandas\u003dinfer_with_pandas,\n\u001b[1;32m    407\u001b[0m                           \u001b[0msampling\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/dataiku/Design/dataiku-dss-9.0.3-osx/python/dataiku/core/dataset.py\u001b[0m in \u001b[0;36m_get_dataframe_schema\u001b[0;34m(self, columns, parse_dates, infer_with_pandas, bool_as_str)\u001b[0m\n\u001b[1;32m    520\u001b[0m                                                    columns, parse_dates, infer_with_pandas, bool_as_str)\n\u001b[1;32m    521\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 522\u001b[0;31m             return Dataset.get_dataframe_schema_st(self.read_schema(),\n\u001b[0m\u001b[1;32m    523\u001b[0m                                                    columns, parse_dates, infer_with_pandas, bool_as_str)\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/dataiku/Design/dataiku-dss-9.0.3-osx/python/dataiku/core/dataset.py\u001b[0m in \u001b[0;36mread_schema\u001b[0;34m(self, raise_if_empty)\u001b[0m\n\u001b[1;32m    336\u001b[0m             self.cols \u003d intercom.jek_or_backend_json_call(\"datasets/get-schema/\", data\u003d{\n\u001b[1;32m    337\u001b[0m                 \u001b[0;34m\"fullDatasetName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 338\u001b[0;31m             }, err_msg\u003d\u0027Unable to fetch schema for %s\u0027%(self.name)).get(\"columns\")\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_if_empty\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m\u003d\u003d\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/dataiku/Design/dataiku-dss-9.0.3-osx/python/dataiku/core/intercom.py\u001b[0m in \u001b[0;36mjek_or_backend_json_call\u001b[0;34m(path, data, err_msg, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjek_json_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 387\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackend_json_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbackend_get_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/dataiku/Design/dataiku-dss-9.0.3-osx/python/dataiku/core/intercom.py\u001b[0m in \u001b[0;36mbackend_json_call\u001b[0;34m(path, data, err_msg, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbackend_json_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 378\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_handle_json_resp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_api_post_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjek_json_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/dataiku/Design/dataiku-dss-9.0.3-osx/python/dataiku/core/intercom.py\u001b[0m in \u001b[0;36m_handle_json_resp\u001b[0;34m(resp, err_msg)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0merr_data\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 450\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No details\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Unable to fetch schema for RAMENMEITEN.ramen_clusters_named: b\u0027Ticket not given or unrecognized. Force reload the notebook.\u0027"
          ],
          "ename": "Exception"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client \u003d dataiku.api_client()\nproject \u003d client.get_project(dataiku.get_custom_variables()[\u0027projectKey\u0027])\nproject_variables \u003d project.get_variables()\nclusters_to_select \u003d project_variables[\u0027standard\u0027][\u0027clusters_to_select\u0027]\nlist_vocabs \u003d df[df[\u0027cluster_labels\u0027].isin([\u0027営業形態\u0027, \u0027味・具材\u0027])][\u0027words_concat\u0027].values"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ramen_word \u003d list_vocabs[0].split(\",\") + list_vocabs[1].split(\",\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "folder_path \u003d dataiku.Folder(\"aLTWBozg\").get_path()\ntext_path \u003d folder_path + \"/ramen_corpus.txt\""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "f \u003d open(text_path,\u0027r\u0027,encoding\u003d\"utf-8\")\ntrainings \u003d []"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for i,data in enumerate(f):\n    word \u003d data.replace(\"\u0027\",\u0027\u0027).replace(\u0027[\u0027,\u0027\u0027).replace(\u0027]\u0027,\u0027\u0027).replace(\u0027 \u0027,\u0027\u0027).replace(\u0027\\n\u0027,\u0027\u0027).split(\",\")\n    trainings.append([i for i in word if i in ramen_word])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "len(trainings)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dictionary \u003d corpora.Dictionary(trainings)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dictionary.num_docs, dictionary.num_pos"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# saving the dictionary in a folder\n# for later use\nfolder_path \u003d dataiku.Folder(\"POe5uF4H\").get_path()\nfilename \u003d folder_path + \"/ramen_dictionary\"\ndictionary.save(filename)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "corpus \u003d list(map(dictionary.doc2bow, trainings))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_model \u003d models.TfidfModel(corpus) # fit tfidf model\n\n# saving tf-idf model\ntf_idf_folder_path \u003d dataiku.Folder(\"tMMk2S0T\").get_path()\npath_tf_idf \u003d tf_idf_folder_path + \"/tf_idf\"\ntest_model.save(path_tf_idf)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "corpus_tfidf \u003d test_model[corpus] # apply model to the corpus (just like \u0027transform\u0027 in scikit-learn)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# id-\u003e単語へ変換\ntexts_tfidf \u003d [] # id -\u003e 単語表示に変えた文書ごとのTF-IDF\nfor doc in corpus_tfidf:\n    text_tfidf \u003d []\n    for word in doc:\n        text_tfidf.append([dictionary[word[0]],word[1]])\n    texts_tfidf.append(text_tfidf)\n\nfrom operator import itemgetter\n\ntexts_tfidf_sorted_top20 \u003d []\n\n# TF-IDF値を高い順に並び替え上位単語20個に絞る。\n# 各ラーメン店のレビューにおいて、TF-IDF値の高い20単語だけが残る。\nfor i in range(len(texts_tfidf)):\n    soted \u003d sorted(texts_tfidf[i], key\u003ditemgetter(1), reverse\u003dTrue)\n    soted_top20 \u003d soted[:20]\n    word_list \u003d []\n    for k in range(len(soted_top20)):\n        word \u003d soted_top20[k][0]\n        word_list.append(word)\n    texts_tfidf_sorted_top20.append(word_list)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ramen_by_restaurant \u003d raw_ramen_df.groupby([\u0027store_name\u0027, \u0027address\u0027, \u0027ward\u0027, \u0027score\u0027, \u0027review_cnt\u0027])[\u0027review\u0027].apply(list).apply(\u0027 \u0027.join).reset_index().sort_values(\u0027score\u0027, ascending\u003dFalse)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ramen_by_restaurant.shape"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ramen_by_restaurant.head()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ramen_by_restaurant[\u0027texts_tfidf_sorted_top20\u0027] \u003d texts_tfidf_sorted_top20"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ramen_by_restaurant[\u0027id\u0027] \u003d [\u0027ID-\u0027 + str(i + 1).zfill(6) for i in range(len(ramen_by_restaurant.index))]"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ramen_by_restaurant \u003d ramen_by_restaurant.reset_index(drop\u003dTrue)\n\n\npy_recipe_output \u003d dataiku.Dataset(\"reviews_TF_IDF\")\npy_recipe_output.write_with_schema(ramen_by_restaurant)"
      ],
      "outputs": []
    }
  ]
}