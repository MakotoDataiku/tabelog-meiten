{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (env japan-nlp)",
      "name": "py-dku-venv-japan-nlp",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.6.8",
      "name": "python",
      "pygments_lexer": "ipython3",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "tags": [
      "recipe-editor"
    ],
    "associatedRecipe": "compute_recommendation",
    "createdOn": 1623429585049,
    "hide_input": false,
    "customFields": {},
    "creator": "admin",
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 49,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\nfrom gensim.models import word2vec\nimport itertools\nfrom itertools import product\nfrom itertools import combinations \nfrom tqdm import tqdm"
      ],
      "outputs": []
    },
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def cos_sim(v1, v2):\n    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
      ],
      "outputs": []
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs\nmodel_folder_path \u003d dataiku.Folder(\"m9JZdV7b\").get_path()\nmodel_path \u003d model_folder_path + \"/word2vec_ramen_model.model\"\nramen_model \u003d word2vec.Word2Vec.load(model_path)"
      ],
      "outputs": []
    },
    {
      "execution_count": 4,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "reviews_TF_IDF \u003d dataiku.Dataset(\"reviews_TF_IDF\")\ndf \u003d reviews_TF_IDF.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 5,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "metadata": {},
          "data": {
            "text/plain": "          store_name                      address  ward  score  review_cnt                                             review                           texts_tfidf_sorted_top20         id\n0      手打式超多加水麺 ののくら  東京都葛飾区亀有3-11-11マーベラス大協ビル 1F  東京都内   3.98         479  2020年、ラーメン103杯目(^^)本日、朝イチで営業を済ませ、次の打ち合わせまで時間が空...  [\u0027うま味\u0027, \u0027えのき\u0027, \u0027パイン\u0027, \u0027町田\u0027, \u0027仲見世商店街\u0027, \u0027町田駅\u0027, \u0027...  ID-000001\n1  Homemade Ramen 麦苗             東京都品川区南大井6-11-10  東京都内   3.97         731  2020/08/03(月)5度目の訪問！現在は蜜を避けるために、事前記帳(予約)式になってい...  [\u0027afuri\u0027, \u0027恵比寿\u0027, \u0027柚子\u0027, \u0027中村屋\u0027, \u0027利山\u0027, \u0027中村\u0027, \u0027天然水...  ID-000002\n2            麺尊 RAGE    東京都杉並区松庵3-37-22レンツェン松庵 1F  東京都内   3.96         723  5年連続で「ミシュランガイド東京」のビブグルマンに掲載され、「The Tabelog Awa...  [\u0027江戸川橋\u0027, \u0027油そば\u0027, \u0027中華そば\u0027, \u0027江戸川橋駅\u0027, \u0027神楽\u0027, \u0027そば\u0027, \u0027...  ID-000003\n3             らぁ麺や 嶋              東京都渋谷区本町3-41-12  東京都内   3.95         177  今年、西新宿五丁目に新しいラーメン屋が出来た。まだ1年も経っていないだろうにすでに期待度が非...  [\u0027記帳\u0027, \u0027いりこ\u0027, \u0027黒毛和牛\u0027, \u0027ウェイティング\u0027, \u0027火山\u0027, \u0027ボード\u0027, ...  ID-000004\n4      宍道湖しじみ中華蕎麦 琥珀               東京都大田区西六郷2-1-3  東京都内   3.95         296  本日は貴重な平日のお休みだった為、普段は中々足を運ぶ事の出来ない蒲田方面へ。11時40分に蒲...  [\u0027黒毛和牛\u0027, \u0027soba\u0027, \u0027代々木上原\u0027, \u0027トリュフ\u0027, \u0027青森シャモロック\u0027, ...  ID-000005",
            "text/html": "\n            \u003cbutton style\u003d\"display:none\" \n            class\u003d\"btn btn-default ipython-export-btn\" \n            id\u003d\"btn-df-669b0202-ca76-4677-9004-5cb40f9e0a66\" \n            onclick\u003d\"_export_df(\u0027669b0202-ca76-4677-9004-5cb40f9e0a66\u0027)\"\u003e\n                Export dataframe\n            \u003c/button\u003e\n            \n            \u003cscript\u003e\n                \n                function _check_export_df_possible(dfid,yes_fn,no_fn) {\n                    console.log(\u0027Checking dataframe exportability...\u0027)\n                    if(!IPython || !IPython.notebook || !IPython.notebook.kernel || !IPython.notebook.kernel) {\n                        console.log(\u0027Export is not possible (IPython kernel is not available)\u0027)\n                        if(no_fn) {\n                            no_fn();\n                        }\n                    } else {\n                        var pythonCode \u003d \u0027from dataiku.notebook.export import IPythonExporter;IPythonExporter._check_export_stdout(\"\u0027+dfid+\u0027\")\u0027;\n                        IPython.notebook.kernel.execute(pythonCode,{iopub: {output: function(resp) {\n                            console.info(\"Exportability response\", resp);\n                            var size \u003d /^([0-9]+)x([0-9]+)$/.exec(resp.content.data || resp.content.text)\n                            if(!size) {\n                                console.log(\u0027Export is not possible (dataframe is not in-memory anymore)\u0027)\n                                if(no_fn) {\n                                    no_fn();\n                                }\n                            } else {\n                                console.log(\u0027Export is possible\u0027)\n                                if(yes_fn) {\n                                    yes_fn(1*size[1],1*size[2]);\n                                }\n                            }\n                        }}});\n                    }\n                }\n            \n                function _export_df(dfid) {\n                    \n                    var btn \u003d $(\u0027#btn-df-\u0027+dfid);\n                    var btns \u003d $(\u0027.ipython-export-btn\u0027);\n                    \n                    _check_export_df_possible(dfid,function() {\n                        \n                        window.parent.openExportModalFromIPython(\u0027Pandas dataframe\u0027,function(data) {\n                            btns.prop(\u0027disabled\u0027,true);\n                            btn.text(\u0027Exporting...\u0027);\n                            var command \u003d \u0027from dataiku.notebook.export import IPythonExporter;IPythonExporter._run_export(\"\u0027+dfid+\u0027\",\"\u0027+data.exportId+\u0027\")\u0027;\n                            var callback \u003d {iopub:{output: function(resp) {\n                                console.info(\"CB resp:\", resp);\n                                _check_export_df_possible(dfid,function(rows, cols) {\n                                    $(\u0027#btn-df-\u0027+dfid)\n                                        .css(\u0027display\u0027,\u0027inline-block\u0027)\n                                        .text(\u0027Export this dataframe (\u0027+rows+\u0027 rows, \u0027+cols+\u0027 cols)\u0027)\n                                        .prop(\u0027disabled\u0027,false);\n                                },function() {\n                                    $(\u0027#btn-df-\u0027+dfid).css(\u0027display\u0027,\u0027none\u0027);\n                                });\n                            }}};\n                            IPython.notebook.kernel.execute(command,callback,{silent:false}); // yes, silent now defaults to true. figures.\n                        });\n                    \n                    }, function(){\n                            alert(\u0027Unable to export : the Dataframe object is not loaded in memory\u0027);\n                            btn.css(\u0027display\u0027,\u0027none\u0027);\n                    });\n                    \n                }\n                \n                (function(dfid) {\n                \n                    var retryCount \u003d 10;\n                \n                    function is_valid_websock(s) {\n                        return s \u0026\u0026 s.readyState\u003d\u003d1;\n                    }\n                \n                    function check_conn() {\n                        \n                        if(!IPython || !IPython.notebook) {\n                            // Don\u0027t even try to go further\n                            return;\n                        }\n                        \n                        // Check if IPython is ready\n                        console.info(\"Checking conn ...\")\n                        if(IPython.notebook.kernel\n                        \u0026\u0026 IPython.notebook.kernel\n                        \u0026\u0026 is_valid_websock(IPython.notebook.kernel.ws)\n                        ) {\n                            \n                            _check_export_df_possible(dfid,function(rows, cols) {\n                                $(\u0027#btn-df-\u0027+dfid).css(\u0027display\u0027,\u0027inline-block\u0027);\n                                $(\u0027#btn-df-\u0027+dfid).text(\u0027Export this dataframe (\u0027+rows+\u0027 rows, \u0027+cols+\u0027 cols)\u0027);\n                            });\n                            \n                        } else {\n                            console.info(\"Conditions are not ok\", IPython.notebook.kernel);\n                            \n                            // Retry later\n                            \n                            if(retryCount\u003e0) {\n                                setTimeout(check_conn,500);\n                                retryCount--;\n                            }\n                            \n                        }\n                    };\n                    \n                    setTimeout(check_conn,100);\n                    \n                })(\"669b0202-ca76-4677-9004-5cb40f9e0a66\");\n                \n            \u003c/script\u003e\n            \n        \u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style\u003d\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003estore_name\u003c/th\u003e\n      \u003cth\u003eaddress\u003c/th\u003e\n      \u003cth\u003eward\u003c/th\u003e\n      \u003cth\u003escore\u003c/th\u003e\n      \u003cth\u003ereview_cnt\u003c/th\u003e\n      \u003cth\u003ereview\u003c/th\u003e\n      \u003cth\u003etexts_tfidf_sorted_top20\u003c/th\u003e\n      \u003cth\u003eid\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e手打式超多加水麺 ののくら\u003c/td\u003e\n      \u003ctd\u003e東京都葛飾区亀有3-11-11マーベラス大協ビル 1F\u003c/td\u003e\n      \u003ctd\u003e東京都内\u003c/td\u003e\n      \u003ctd\u003e3.98\u003c/td\u003e\n      \u003ctd\u003e479\u003c/td\u003e\n      \u003ctd\u003e2020年、ラーメン103杯目(^^)本日、朝イチで営業を済ませ、次の打ち合わせまで時間が空...\u003c/td\u003e\n      \u003ctd\u003e[\u0027うま味\u0027, \u0027えのき\u0027, \u0027パイン\u0027, \u0027町田\u0027, \u0027仲見世商店街\u0027, \u0027町田駅\u0027, \u0027...\u003c/td\u003e\n      \u003ctd\u003eID-000001\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003eHomemade Ramen 麦苗\u003c/td\u003e\n      \u003ctd\u003e東京都品川区南大井6-11-10\u003c/td\u003e\n      \u003ctd\u003e東京都内\u003c/td\u003e\n      \u003ctd\u003e3.97\u003c/td\u003e\n      \u003ctd\u003e731\u003c/td\u003e\n      \u003ctd\u003e2020/08/03(月)5度目の訪問！現在は蜜を避けるために、事前記帳(予約)式になってい...\u003c/td\u003e\n      \u003ctd\u003e[\u0027afuri\u0027, \u0027恵比寿\u0027, \u0027柚子\u0027, \u0027中村屋\u0027, \u0027利山\u0027, \u0027中村\u0027, \u0027天然水...\u003c/td\u003e\n      \u003ctd\u003eID-000002\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e麺尊 RAGE\u003c/td\u003e\n      \u003ctd\u003e東京都杉並区松庵3-37-22レンツェン松庵 1F\u003c/td\u003e\n      \u003ctd\u003e東京都内\u003c/td\u003e\n      \u003ctd\u003e3.96\u003c/td\u003e\n      \u003ctd\u003e723\u003c/td\u003e\n      \u003ctd\u003e5年連続で「ミシュランガイド東京」のビブグルマンに掲載され、「The Tabelog Awa...\u003c/td\u003e\n      \u003ctd\u003e[\u0027江戸川橋\u0027, \u0027油そば\u0027, \u0027中華そば\u0027, \u0027江戸川橋駅\u0027, \u0027神楽\u0027, \u0027そば\u0027, \u0027...\u003c/td\u003e\n      \u003ctd\u003eID-000003\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003eらぁ麺や 嶋\u003c/td\u003e\n      \u003ctd\u003e東京都渋谷区本町3-41-12\u003c/td\u003e\n      \u003ctd\u003e東京都内\u003c/td\u003e\n      \u003ctd\u003e3.95\u003c/td\u003e\n      \u003ctd\u003e177\u003c/td\u003e\n      \u003ctd\u003e今年、西新宿五丁目に新しいラーメン屋が出来た。まだ1年も経っていないだろうにすでに期待度が非...\u003c/td\u003e\n      \u003ctd\u003e[\u0027記帳\u0027, \u0027いりこ\u0027, \u0027黒毛和牛\u0027, \u0027ウェイティング\u0027, \u0027火山\u0027, \u0027ボード\u0027, ...\u003c/td\u003e\n      \u003ctd\u003eID-000004\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e宍道湖しじみ中華蕎麦 琥珀\u003c/td\u003e\n      \u003ctd\u003e東京都大田区西六郷2-1-3\u003c/td\u003e\n      \u003ctd\u003e東京都内\u003c/td\u003e\n      \u003ctd\u003e3.95\u003c/td\u003e\n      \u003ctd\u003e296\u003c/td\u003e\n      \u003ctd\u003e本日は貴重な平日のお休みだった為、普段は中々足を運ぶ事の出来ない蒲田方面へ。11時40分に蒲...\u003c/td\u003e\n      \u003ctd\u003e[\u0027黒毛和牛\u0027, \u0027soba\u0027, \u0027代々木上原\u0027, \u0027トリュフ\u0027, \u0027青森シャモロック\u0027, ...\u003c/td\u003e\n      \u003ctd\u003eID-000005\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          },
          "execution_count": 5
        }
      ]
    },
    {
      "execution_count": 6,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tripAdvisor_path \u003d dataiku.Folder(\"FXMfF0DU\").get_path() + \"/TripAdvisor_top_TFIDF_words.txt\"\nf \u003d open(tripAdvisor_path,\u0027r\u0027,encoding\u003d\"utf-8\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 7,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "words_ta \u003d []\nfor i,data in enumerate(f):\n    word \u003d data.replace(\"\u0027\",\u0027\u0027).replace(\u0027[\u0027,\u0027\u0027).replace(\u0027]\u0027,\u0027\u0027).replace(\u0027 \u0027,\u0027\u0027).replace(\u0027\\n\u0027,\u0027\u0027)\n    words_ta.append(word)"
      ],
      "outputs": []
    },
    {
      "execution_count": 8,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "words_ta"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "metadata": {},
          "data": {
            "text/plain": "[\u0027ロンドン\u0027,\n \u0027ハマチ\u0027,\n \u0027うなぎ\u0027,\n \u0027疑い\u0027,\n \u0027メインディッシュ\u0027,\n \u0027宝石\u0027,\n \u0027すし\u0027,\n \u0027お刺身\u0027,\n \u0027効率的\u0027,\n \u0027黒ごま\u0027,\n \u0027リラックス\u0027,\n \u0027共有\u0027,\n \u0027汁物\u0027,\n \u0027サーモン\u0027,\n \u0027いたこと\u0027,\n \u0027推薦\u0027,\n \u0027しみ\u0027,\n \u0027前菜\u0027,\n \u0027盛り合わせ\u0027,\n \u0027高品質\u0027]"
          },
          "execution_count": 8
        }
      ]
    },
    {
      "execution_count": 9,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "word_ta_vectors \u003d [ramen_model.wv[w] for w in words_ta]"
      ],
      "outputs": []
    },
    {
      "execution_count": 11,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "word_list \u003d []\narr \u003d df[\u0027texts_tfidf_sorted_top20\u0027].values\nfor a in arr:\n    l \u003d a.replace(\"\u0027\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").split(\",\")\n    word_list.append(l)"
      ],
      "outputs": []
    },
    {
      "execution_count": 13,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "word_list.append(words_ta)"
      ],
      "outputs": []
    },
    {
      "execution_count": 18,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "i \u003d 0\nfor l in word_list:\n    for w in l:\n        i +\u003d 1"
      ],
      "outputs": []
    },
    {
      "execution_count": 21,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"{} words detected before removing duplicates\".format(i))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "14740 words detected before removing duplicates\n"
        }
      ]
    },
    {
      "execution_count": 22,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "uniq_words \u003d list(set(itertools.chain.from_iterable(word_list)))"
      ],
      "outputs": []
    },
    {
      "execution_count": 23,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"{} words detected before removing duplicates\".format(len(uniq_words)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "5435 words detected before removing duplicates\n"
        }
      ]
    },
    {
      "execution_count": 26,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def combine(arr, s): \n    return list(combinations(arr, s)) "
      ],
      "outputs": []
    },
    {
      "execution_count": 27,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "array \u003d [21, 18, 19] \nset \u003d 2\nprint(combine(array, set))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[(21, 18), (21, 19), (18, 19)]\n"
        }
      ]
    },
    {
      "execution_count": 28,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "len(combine(uniq_words, 2))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "metadata": {},
          "data": {
            "text/plain": "14766895"
          },
          "execution_count": 28
        }
      ]
    },
    {
      "execution_count": 39,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for w1, w2 in product(array, repeat\u003d2):\n    print(w1, w2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "21 21\n21 18\n21 19\n18 21\n18 18\n18 19\n19 21\n19 18\n19 19\n"
        }
      ]
    },
    {
      "execution_count": 33,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "i \u003d 0\nfor w1, w2 in product(uniq_words, repeat\u003d2):\n    i +\u003d 1"
      ],
      "outputs": []
    },
    {
      "execution_count": 34,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "i"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "metadata": {},
          "data": {
            "text/plain": "29539225"
          },
          "execution_count": 34
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#scores \u003d {}\n#for word1, word2 in product(uniq_words, repeat\u003d2):\n#    # print(word1, word2)\n#    scores[(word1, word2)] \u003d  cos_sim(ramen_model.wv[word1], ramen_model.wv[word2])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scores \u003d {}\nfor touple in tqdm(combine(uniq_words, 2)):\n    # print(word1, word2)\n    similarity \u003d cos_sim(ramen_model.wv[touple[0]], ramen_model.wv[touple[1]])\n    scores[(touple[0], touple[1])] \u003d similarity\n    scores[(touple[1], touple[0])] \u003d similarity"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": " 71%|███████   | 10430666/14766895 [04:48\u003c02:19, 31007.74it/s]"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scores"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "avg_avg_scores \u003d []\nfor word_2 in words_ta:\n    avg_scores \u003d []\n    for review in df[\"texts_tfidf_sorted_top20\"].values:\n        review \u003d review.replace(\"\u0027\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").split(\",\")\n        word_cross_scores \u003d []\n        for word_1 in review:\n            score \u003d scores[(word_1, word_2)]\n            word_cross_scores.append(score)\n        avg_scores.append(np.mean(word_cross_scores))\n    avg_avg_scores.append(np.mean(avg_scores))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "avg_avg_scores \u003d []\nfor review in df[\"texts_tfidf_sorted_top20\"].values:\n    review \u003d review.replace(\"\u0027\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").split(\",\")\n    avg_scores \u003d []\n    for word_1 in review:\n        word_cross_scores \u003d []\n        for word_2 in words_ta:\n            score \u003d scores[(word_1, word_2)]\n            word_cross_scores.append(score)\n        avg_scores.append(np.mean(word_cross_scores))\n    avg_avg_scores.append(np.mean(avg_scores))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "len(avg_avg_scores)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[\u0027similarity_score\u0027] \u003d avg_avg_scores"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "recommendation \u003d dataiku.Dataset(\"recommendation\")\nrecommendation.write_with_schema(df)"
      ],
      "outputs": []
    }
  ]
}