{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (env japan-nlp)",
      "name": "py-dku-venv-japan-nlp",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.6.8",
      "name": "python",
      "pygments_lexer": "ipython3",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "tags": [
      "recipe-editor"
    ],
    "associatedRecipe": "compute_similarity_scores",
    "createdOn": 1622567195205,
    "hide_input": false,
    "modifiedBy": "admin",
    "customFields": {},
    "creator": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 31,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\nfrom itertools import product\nfrom gensim.models import word2vec\nimport itertools\nfrom tqdm import tqdm "
      ],
      "outputs": []
    },
    {
      "execution_count": 24,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read recipe inputs\nreviews_TF_IDF \u003d dataiku.Dataset(\"reviews_TF_IDF\")\ndf \u003d reviews_TF_IDF.get_dataframe()"
      ],
      "outputs": []
    },
    {
      "execution_count": 25,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "folder_path \u003d dataiku.Folder(\"m9JZdV7b\").get_path()\nmodel_path \u003d folder_path + \"/word2vec_ramen_model.model\"\nramen_model \u003d word2vec.Word2Vec.load(model_path)"
      ],
      "outputs": []
    },
    {
      "execution_count": 26,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "store_cross \u003d []\nfor ids in product(df[\u0027id\u0027], repeat\u003d2):\n    store_cross.append(ids)"
      ],
      "outputs": []
    },
    {
      "execution_count": 27,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "store_cross_df \u003d pd.DataFrame(store_cross, columns\u003d[\u0027id_x\u0027, \u0027id_y\u0027])"
      ],
      "outputs": []
    },
    {
      "execution_count": 28,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "store_cross_detail \u003d store_cross_df.merge(df[[\u0027id\u0027,\u0027store_name\u0027,\u0027score\u0027,\u0027review_cnt\u0027,\u0027texts_tfidf_sorted_top20\u0027]], \n                                          how\u003d\u0027inner\u0027, \n                                          left_on\u003d\u0027id_x\u0027, \n                                          right_on\u003d\u0027id\u0027).drop(columns\u003d\u0027id\u0027).merge(df[[\u0027id\u0027,\u0027store_name\u0027,\u0027score\u0027,\u0027review_cnt\u0027,\u0027texts_tfidf_sorted_top20\u0027]], \n                                                                                  how\u003d\u0027inner\u0027, \n                                                                                  left_on\u003d\u0027id_y\u0027, \n                                                                                  right_on\u003d\u0027id\u0027).drop(columns\u003d\u0027id\u0027)"
      ],
      "outputs": []
    },
    {
      "execution_count": 29,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "store_cross_detail.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "metadata": {},
          "data": {
            "text/plain": "        id_x       id_y       store_name_x  score_x  review_cnt_x                         texts_tfidf_sorted_top20_x   store_name_y  score_y  review_cnt_y                         texts_tfidf_sorted_top20_y\n0  ID-000001  ID-000001      手打式超多加水麺 ののくら     3.98           479  [\u0027ワンタン\u0027, \u0027ストーブ\u0027, \u0027予約\u0027, \u00272時間\u0027, \u00271時間\u0027, \u0027記帳\u0027, \u00272時...  手打式超多加水麺 ののくら     3.98           479  [\u0027ワンタン\u0027, \u0027ストーブ\u0027, \u0027予約\u0027, \u00272時間\u0027, \u00271時間\u0027, \u0027記帳\u0027, \u00272時...\n1  ID-000002  ID-000001  Homemade Ramen 麦苗     3.97           731  [\u0027記帳\u0027, \u0027ボード\u0027, \u0027ウェイティング\u0027, \u0027深谷\u0027, \u00279時\u0027, \u0027記名\u0027, \u0027ワン...  手打式超多加水麺 ののくら     3.98           479  [\u0027ワンタン\u0027, \u0027ストーブ\u0027, \u0027予約\u0027, \u00272時間\u0027, \u00271時間\u0027, \u0027記帳\u0027, \u00272時...\n2  ID-000003  ID-000001            麺尊 RAGE     3.96           723  [\u0027金華\u0027, \u0027ハム\u0027, \u0027ロック\u0027, \u0027穂先\u0027, \u0027燻製\u0027, \u0027レモン\u0027, \u0027豚バラ\u0027, ...  手打式超多加水麺 ののくら     3.98           479  [\u0027ワンタン\u0027, \u0027ストーブ\u0027, \u0027予約\u0027, \u00272時間\u0027, \u00271時間\u0027, \u0027記帳\u0027, \u00272時...\n3  ID-000004  ID-000001      宍道湖しじみ中華蕎麦 琥珀     3.95           296  [\u0027シジミ\u0027, \u0027バラ\u0027, \u0027焼き\u0027, \u0027紫玉ねぎ\u0027, \u0027吊し\u0027, \u0027菅野\u0027, \u0027ワンタン\u0027...  手打式超多加水麺 ののくら     3.98           479  [\u0027ワンタン\u0027, \u0027ストーブ\u0027, \u0027予約\u0027, \u00272時間\u0027, \u00271時間\u0027, \u0027記帳\u0027, \u00272時...\n4  ID-000005  ID-000001             らぁ麺や 嶋     3.95           177  [\u0027記帳\u0027, \u00274点\u0027, \u0027細切り\u0027, \u0027記入\u0027, \u0027炭火焼き\u0027, \u0027昆布\u0027, \u0027燻製\u0027, ...  手打式超多加水麺 ののくら     3.98           479  [\u0027ワンタン\u0027, \u0027ストーブ\u0027, \u0027予約\u0027, \u00272時間\u0027, \u00271時間\u0027, \u0027記帳\u0027, \u00272時...",
            "text/html": "\n            \u003cbutton style\u003d\"display:none\" \n            class\u003d\"btn btn-default ipython-export-btn\" \n            id\u003d\"btn-df-76086327-4431-48cc-9c1d-6ed29d4a2490\" \n            onclick\u003d\"_export_df(\u002776086327-4431-48cc-9c1d-6ed29d4a2490\u0027)\"\u003e\n                Export dataframe\n            \u003c/button\u003e\n            \n            \u003cscript\u003e\n                \n                function _check_export_df_possible(dfid,yes_fn,no_fn) {\n                    console.log(\u0027Checking dataframe exportability...\u0027)\n                    if(!IPython || !IPython.notebook || !IPython.notebook.kernel || !IPython.notebook.kernel) {\n                        console.log(\u0027Export is not possible (IPython kernel is not available)\u0027)\n                        if(no_fn) {\n                            no_fn();\n                        }\n                    } else {\n                        var pythonCode \u003d \u0027from dataiku.notebook.export import IPythonExporter;IPythonExporter._check_export_stdout(\"\u0027+dfid+\u0027\")\u0027;\n                        IPython.notebook.kernel.execute(pythonCode,{iopub: {output: function(resp) {\n                            console.info(\"Exportability response\", resp);\n                            var size \u003d /^([0-9]+)x([0-9]+)$/.exec(resp.content.data || resp.content.text)\n                            if(!size) {\n                                console.log(\u0027Export is not possible (dataframe is not in-memory anymore)\u0027)\n                                if(no_fn) {\n                                    no_fn();\n                                }\n                            } else {\n                                console.log(\u0027Export is possible\u0027)\n                                if(yes_fn) {\n                                    yes_fn(1*size[1],1*size[2]);\n                                }\n                            }\n                        }}});\n                    }\n                }\n            \n                function _export_df(dfid) {\n                    \n                    var btn \u003d $(\u0027#btn-df-\u0027+dfid);\n                    var btns \u003d $(\u0027.ipython-export-btn\u0027);\n                    \n                    _check_export_df_possible(dfid,function() {\n                        \n                        window.parent.openExportModalFromIPython(\u0027Pandas dataframe\u0027,function(data) {\n                            btns.prop(\u0027disabled\u0027,true);\n                            btn.text(\u0027Exporting...\u0027);\n                            var command \u003d \u0027from dataiku.notebook.export import IPythonExporter;IPythonExporter._run_export(\"\u0027+dfid+\u0027\",\"\u0027+data.exportId+\u0027\")\u0027;\n                            var callback \u003d {iopub:{output: function(resp) {\n                                console.info(\"CB resp:\", resp);\n                                _check_export_df_possible(dfid,function(rows, cols) {\n                                    $(\u0027#btn-df-\u0027+dfid)\n                                        .css(\u0027display\u0027,\u0027inline-block\u0027)\n                                        .text(\u0027Export this dataframe (\u0027+rows+\u0027 rows, \u0027+cols+\u0027 cols)\u0027)\n                                        .prop(\u0027disabled\u0027,false);\n                                },function() {\n                                    $(\u0027#btn-df-\u0027+dfid).css(\u0027display\u0027,\u0027none\u0027);\n                                });\n                            }}};\n                            IPython.notebook.kernel.execute(command,callback,{silent:false}); // yes, silent now defaults to true. figures.\n                        });\n                    \n                    }, function(){\n                            alert(\u0027Unable to export : the Dataframe object is not loaded in memory\u0027);\n                            btn.css(\u0027display\u0027,\u0027none\u0027);\n                    });\n                    \n                }\n                \n                (function(dfid) {\n                \n                    var retryCount \u003d 10;\n                \n                    function is_valid_websock(s) {\n                        return s \u0026\u0026 s.readyState\u003d\u003d1;\n                    }\n                \n                    function check_conn() {\n                        \n                        if(!IPython || !IPython.notebook) {\n                            // Don\u0027t even try to go further\n                            return;\n                        }\n                        \n                        // Check if IPython is ready\n                        console.info(\"Checking conn ...\")\n                        if(IPython.notebook.kernel\n                        \u0026\u0026 IPython.notebook.kernel\n                        \u0026\u0026 is_valid_websock(IPython.notebook.kernel.ws)\n                        ) {\n                            \n                            _check_export_df_possible(dfid,function(rows, cols) {\n                                $(\u0027#btn-df-\u0027+dfid).css(\u0027display\u0027,\u0027inline-block\u0027);\n                                $(\u0027#btn-df-\u0027+dfid).text(\u0027Export this dataframe (\u0027+rows+\u0027 rows, \u0027+cols+\u0027 cols)\u0027);\n                            });\n                            \n                        } else {\n                            console.info(\"Conditions are not ok\", IPython.notebook.kernel);\n                            \n                            // Retry later\n                            \n                            if(retryCount\u003e0) {\n                                setTimeout(check_conn,500);\n                                retryCount--;\n                            }\n                            \n                        }\n                    };\n                    \n                    setTimeout(check_conn,100);\n                    \n                })(\"76086327-4431-48cc-9c1d-6ed29d4a2490\");\n                \n            \u003c/script\u003e\n            \n        \u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style\u003d\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eid_x\u003c/th\u003e\n      \u003cth\u003eid_y\u003c/th\u003e\n      \u003cth\u003estore_name_x\u003c/th\u003e\n      \u003cth\u003escore_x\u003c/th\u003e\n      \u003cth\u003ereview_cnt_x\u003c/th\u003e\n      \u003cth\u003etexts_tfidf_sorted_top20_x\u003c/th\u003e\n      \u003cth\u003estore_name_y\u003c/th\u003e\n      \u003cth\u003escore_y\u003c/th\u003e\n      \u003cth\u003ereview_cnt_y\u003c/th\u003e\n      \u003cth\u003etexts_tfidf_sorted_top20_y\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003eID-000001\u003c/td\u003e\n      \u003ctd\u003eID-000001\u003c/td\u003e\n      \u003ctd\u003e手打式超多加水麺 ののくら\u003c/td\u003e\n      \u003ctd\u003e3.98\u003c/td\u003e\n      \u003ctd\u003e479\u003c/td\u003e\n      \u003ctd\u003e[\u0027ワンタン\u0027, \u0027ストーブ\u0027, \u0027予約\u0027, \u00272時間\u0027, \u00271時間\u0027, \u0027記帳\u0027, \u00272時...\u003c/td\u003e\n      \u003ctd\u003e手打式超多加水麺 ののくら\u003c/td\u003e\n      \u003ctd\u003e3.98\u003c/td\u003e\n      \u003ctd\u003e479\u003c/td\u003e\n      \u003ctd\u003e[\u0027ワンタン\u0027, \u0027ストーブ\u0027, \u0027予約\u0027, \u00272時間\u0027, \u00271時間\u0027, \u0027記帳\u0027, \u00272時...\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003eID-000002\u003c/td\u003e\n      \u003ctd\u003eID-000001\u003c/td\u003e\n      \u003ctd\u003eHomemade Ramen 麦苗\u003c/td\u003e\n      \u003ctd\u003e3.97\u003c/td\u003e\n      \u003ctd\u003e731\u003c/td\u003e\n      \u003ctd\u003e[\u0027記帳\u0027, \u0027ボード\u0027, \u0027ウェイティング\u0027, \u0027深谷\u0027, \u00279時\u0027, \u0027記名\u0027, \u0027ワン...\u003c/td\u003e\n      \u003ctd\u003e手打式超多加水麺 ののくら\u003c/td\u003e\n      \u003ctd\u003e3.98\u003c/td\u003e\n      \u003ctd\u003e479\u003c/td\u003e\n      \u003ctd\u003e[\u0027ワンタン\u0027, \u0027ストーブ\u0027, \u0027予約\u0027, \u00272時間\u0027, \u00271時間\u0027, \u0027記帳\u0027, \u00272時...\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003eID-000003\u003c/td\u003e\n      \u003ctd\u003eID-000001\u003c/td\u003e\n      \u003ctd\u003e麺尊 RAGE\u003c/td\u003e\n      \u003ctd\u003e3.96\u003c/td\u003e\n      \u003ctd\u003e723\u003c/td\u003e\n      \u003ctd\u003e[\u0027金華\u0027, \u0027ハム\u0027, \u0027ロック\u0027, \u0027穂先\u0027, \u0027燻製\u0027, \u0027レモン\u0027, \u0027豚バラ\u0027, ...\u003c/td\u003e\n      \u003ctd\u003e手打式超多加水麺 ののくら\u003c/td\u003e\n      \u003ctd\u003e3.98\u003c/td\u003e\n      \u003ctd\u003e479\u003c/td\u003e\n      \u003ctd\u003e[\u0027ワンタン\u0027, \u0027ストーブ\u0027, \u0027予約\u0027, \u00272時間\u0027, \u00271時間\u0027, \u0027記帳\u0027, \u00272時...\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003eID-000004\u003c/td\u003e\n      \u003ctd\u003eID-000001\u003c/td\u003e\n      \u003ctd\u003e宍道湖しじみ中華蕎麦 琥珀\u003c/td\u003e\n      \u003ctd\u003e3.95\u003c/td\u003e\n      \u003ctd\u003e296\u003c/td\u003e\n      \u003ctd\u003e[\u0027シジミ\u0027, \u0027バラ\u0027, \u0027焼き\u0027, \u0027紫玉ねぎ\u0027, \u0027吊し\u0027, \u0027菅野\u0027, \u0027ワンタン\u0027...\u003c/td\u003e\n      \u003ctd\u003e手打式超多加水麺 ののくら\u003c/td\u003e\n      \u003ctd\u003e3.98\u003c/td\u003e\n      \u003ctd\u003e479\u003c/td\u003e\n      \u003ctd\u003e[\u0027ワンタン\u0027, \u0027ストーブ\u0027, \u0027予約\u0027, \u00272時間\u0027, \u00271時間\u0027, \u0027記帳\u0027, \u00272時...\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003eID-000005\u003c/td\u003e\n      \u003ctd\u003eID-000001\u003c/td\u003e\n      \u003ctd\u003eらぁ麺や 嶋\u003c/td\u003e\n      \u003ctd\u003e3.95\u003c/td\u003e\n      \u003ctd\u003e177\u003c/td\u003e\n      \u003ctd\u003e[\u0027記帳\u0027, \u00274点\u0027, \u0027細切り\u0027, \u0027記入\u0027, \u0027炭火焼き\u0027, \u0027昆布\u0027, \u0027燻製\u0027, ...\u003c/td\u003e\n      \u003ctd\u003e手打式超多加水麺 ののくら\u003c/td\u003e\n      \u003ctd\u003e3.98\u003c/td\u003e\n      \u003ctd\u003e479\u003c/td\u003e\n      \u003ctd\u003e[\u0027ワンタン\u0027, \u0027ストーブ\u0027, \u0027予約\u0027, \u00272時間\u0027, \u00271時間\u0027, \u0027記帳\u0027, \u00272時...\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          },
          "execution_count": 29
        }
      ]
    },
    {
      "execution_count": 30,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# store_cross_detail \u003d store_cross_detail[store_cross_detail[\u0027id_x\u0027].isin(df[\u0027id\u0027].loc[0:50])]\nstore_cross_detail \u003d store_cross_detail.reset_index(drop\u003dTrue).sort_values([\u0027id_x\u0027])"
      ],
      "outputs": []
    },
    {
      "execution_count": 32,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##ラーメン店xに対してラーメン店yの類似度を算出\n#コサイン類似度を算出する関数を定義\ndef cos_sim(v1, v2):\n    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
      ],
      "outputs": []
    },
    {
      "execution_count": 39,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#cossimだけの組み合わせ（同じワード同士の組みあわせがでてくるため）\n#2次元を１次元にする　setが重複を削除てきなやつ。\nuniq_words \u003d list(set(itertools.chain.from_iterable(df[\u0027texts_tfidf_sorted_top20\u0027].values)))\nscores \u003d {}\nfor word1, word2 in product(uniq_words, repeat\u003d2):\n    print(word1, word2)\n    scores[(word1, word2)] \u003d  cos_sim(ramen_model.wv[word1], ramen_model.wv[word2])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "素 素\n"
        },
        {
          "output_type": "error",
          "evalue": "\"word \u0027素\u0027 not in vocabulary\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-39-2c4008f0433c\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniq_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 7\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m\u003d\u001b[0m  \u001b[0mcos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mramen_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mramen_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/dataiku/Design/DATA_DIR/code-envs/python/japan-nlp/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;31m# allow calls like trained_model[\u0027office\u0027], as a shorthand for trained_model[[\u0027office\u0027]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 353\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/dataiku/Design/DATA_DIR/code-envs/python/japan-nlp/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/dataiku/Design/DATA_DIR/code-envs/python/japan-nlp/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word \u0027%s\u0027 not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word \u0027素\u0027 not in vocabulary\""
          ],
          "ename": "KeyError"
        }
      ]
    },
    {
      "execution_count": 50,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[\u0027texts_tfidf_sorted_top20\u0027].values.replace(\"\u0027\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").split(\",\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "evalue": "\u0027numpy.ndarray\u0027 object has no attribute \u0027replace\u0027",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-50-954652a9f90e\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u0027texts_tfidf_sorted_top20\u0027\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\u0027\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: \u0027numpy.ndarray\u0027 object has no attribute \u0027replace\u0027"
          ],
          "ename": "AttributeError"
        }
      ]
    },
    {
      "execution_count": 16,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "avg_avg_scores \u003d []\nfor i in tqdm(range(len(store_cross_detail[\u0027texts_tfidf_sorted_top20_x\u0027]))):\n    avg_scores \u003d []\n    for j in range(len(store_cross_detail[\u0027texts_tfidf_sorted_top20_x\u0027][i])):\n        word_cross_scores \u003d []\n        word_a \u003d store_cross_detail[\u0027texts_tfidf_sorted_top20_x\u0027][i][j]\n        for k in range(len(store_cross_detail[\u0027texts_tfidf_sorted_top20_y\u0027][i])):\n            word_b \u003d store_cross_detail[\u0027texts_tfidf_sorted_top20_y\u0027][i][k]\n            score \u003d scores[(word_a, word_b)]#単語間のスコアを出す。\n            word_cross_scores.append(score)\n        avg_scores.append(np.mean(word_cross_scores))#20個の単語間スコアの平均値\n    avg_avg_scores.append(np.mean(avg_scores))#20個の単語間スコアの平均値の平均値\nstore_cross_detail.insert(6, \u0027avg_cos_sim_rate\u0027, avg_avg_scores)  \n# 「二郎」と類似度が高いラーメン屋を高い順に表示\nstore_cross_detail \u003d store_cross_detail.sort_values([\u0027id_x\u0027, \u0027avg_cos_sim_rate\u0027], ascending\u003d[True, False])\ndf_sim_x \u003d store_cross_detail[store_cross_detail[\u0027store_name_x\u0027].str.contains(\u0027二郎\u0027)]\ndf_sim_x.reset_index(drop\u003dTrue)\n\ndef min_max(x, axis\u003dNone):\n    min \u003d x.min(axis\u003daxis, keepdims\u003dTrue)\n    max \u003d x.max(axis\u003daxis, keepdims\u003dTrue)\n    result \u003d (x-min)/(max-min)\n    return result\nb \u003d df_sim_x[\u0027avg_cos_sim_rate\u0027]\nc \u003d min_max(b.values)\ndf_sim_x.insert(7, \u0027正規化\u0027, c)\ndf_sim_x"
      ],
      "outputs": [
        {
          "output_type": "error",
          "evalue": "name \u0027store_df\u0027 is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-16-ceedbdad15b5\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#cossimだけの組み合わせ（同じワード同士の組みあわせがでてくるため）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#2次元を１次元にする　setが重複を削除てきなやつ。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 12\u001b[0;31m \u001b[0muniq_words\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u0027texts_tfidf_sorted_top20\u0027\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniq_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name \u0027store_df\u0027 is not defined"
          ],
          "ename": "NameError"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute recipe outputs from inputs\n# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n\nsimilarity_scores_df \u003d reviews_TF_IDF_df # For this sample code, simply copy input to output\n\n\n# Write recipe outputs\nsimilarity_scores \u003d dataiku.Dataset(\"similarity_scores\")\nsimilarity_scores.write_with_schema(similarity_scores_df)"
      ],
      "outputs": []
    }
  ]
}